{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restricciones de la Regresión Lineal\n",
    "\n",
    "* Linealidad\n",
    "* Homocedasticidad\n",
    "* Normalidad multivariable\n",
    "* Independencia de los errores\n",
    "* Ausencia de multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos para construir modelos de regresión\n",
    "1. Exahustivo ('All-in' - cases) -> EVITAR\n",
    "    * Conocimiento a priori.\n",
    "    * Necesidad u obliglación.\n",
    "    * Preparación previa para eliminar hacía atrás.\n",
    "\n",
    "2. Eliminación hacía atrás\n",
    "    * Elegir el nivel de significación (SL = 0.05).\n",
    "    * Se calcula el modelo con todas las variables predictoras.\n",
    "    * Considera la variable predictora con el p-value más grande. Si P > SL ---> Next step, de lo contrario finaliza (FIN).\n",
    "    * Se elimina la variable predictora.\n",
    "    * Ajustar el modelo sin dicha variable predictora --> (Paso 3).\n",
    "    \n",
    "3. Selección hacía adelante\n",
    "    * Elegir un nivel de significación (SL = 0.05) para entrar en el modelo.\n",
    "    * Ajustamos todos los modelos de regresión simple y ~ $x_n$ Elegimos el que tiene menos p-value.\n",
    "    * Conservamos esta variable, y ajustamos todos los posibles modelos con una variable extra añadida a las que se tienen.\n",
    "    * Consideramos la variable predictora con el menor p-value. Si P < SL ---> Paso 3, si no a FIN.\n",
    "\n",
    "4. Eliminación Bidireccional\n",
    "    * Seleccionar un nivel de significación para entrar y salir del modelo. (SLenter = 0.05, SLstay = 0.05)\n",
    "    * Pasos de selección hacía adelante (nuevas variables --> P < SLenter).\n",
    "    * Pasos de eliminación hacía atras (variables antiguas --> P < SLstay).\n",
    "    * No hay nuevas variables para entrar ni antiguas para salir.\n",
    "\n",
    "5. Comparación de scores (Todos los modelos posibles)\n",
    "    * Seleccionar un criterio de bondad de ajuste (p.e. criterio de Akaike).\n",
    "    * Construir todos los posibles modelos de regresión: $2^n$ - 1. Ejemplo: 10 columnas --> 1023 modelos.\n",
    "    * Seleccionar el modelo con el mejor criterio elegido\n",
    "    * El modelo está listo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar y leer el dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
